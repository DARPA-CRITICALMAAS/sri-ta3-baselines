{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_dataset()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies presence / absence columns to boolean - geology properties\n",
    "data[\"Geology_Dictionary_Alkalic\"] = data[\"Geology_Dictionary_Alkalic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Anatectic\"] = data[\"Geology_Dictionary_Anatectic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Calcareous\"] = data[\"Geology_Dictionary_Calcareous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Carbonaceous\"] = data[\"Geology_Dictionary_Carbonaceous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Cherty\"] = data[\"Geology_Dictionary_Cherty\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_CoarseClastic\"] = data[\"Geology_Dictionary_CoarseClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Evaporitic\"] = data[\"Geology_Dictionary_Evaporitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Felsic\"] = data[\"Geology_Dictionary_Felsic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_FineClastic\"] = data[\"Geology_Dictionary_FineClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Gneissose\"] = data[\"Geology_Dictionary_Gneissose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Igneous\"] = data[\"Geology_Dictionary_Igneous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Intermediate\"] = data[\"Geology_Dictionary_Intermediate\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Pegmatitic\"] = data[\"Geology_Dictionary_Pegmatitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_RedBed\"] = data[\"Geology_Dictionary_RedBed\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Schistose\"] = data[\"Geology_Dictionary_Schistose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Sedimentary\"] = data[\"Geology_Dictionary_Sedimentary\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_UltramaficMafic\"] = data[\"Geology_Dictionary_UltramaficMafic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "# modifies presence / absence columns to boolean - labels\n",
    "data[\"Training_MVT_Deposit\"] = data[\"Training_MVT_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_MVT_Occurrence\"] = data[\"Training_MVT_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Deposit\"] = data[\"Training_CD_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Occurrence\"] = data[\"Training_CD_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects the data /labels used for CD WOE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = utils.load_features_dict(type='CD', baseline='preferred')\n",
    "data_filtered, cols = utils.extract_cols(data, cols_dict)\n",
    "\n",
    "# converts the categorical variables to one-hot encoded vectors for ML compatibility\n",
    "data_filtered = pd.get_dummies(data_filtered, columns=['Geology_Lithology_Majority','Geology_Lithology_Minority','Geology_Period_Maximum_Majority','Geology_Period_Minimum_Majority'], prefix=['Geology_Lithology_Majority','Geology_Lithology_Minority','Geology_Period_Maximum_Majority','Geology_Period_Minimum_Majority'])\n",
    "\n",
    "data_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function finds all the neighbors and creates a new column \"CD_Deposit\".\n",
    "Original paper treats neighbors of polygons with \"Training_CD_Deposit=Present\" and \"Training_CD_Occurrence=Present\" as mineral present, \"CD_Deposit=Present\" (note: now Deposit means - Deposit, Occurrence, or their neighbor). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.neighbor_deposits(data_filtered, type='CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered['CD_Deposit'].value_counts())\n",
    "print(data_filtered['CD_Deposit_wNeighbors'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = data_filtered['CD_Deposit_wNeighbors']\n",
    "data_filtered = data_filtered.drop(columns=['H3_Geometry', 'Training_CD_Deposit', 'Training_CD_Occurrence', 'CD_Deposit', 'CD_Deposit_wNeighbors'])\n",
    "cols = cols[1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the dataset has MANY outliers, as reported in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove these outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.tukey_remove_outliers(data_filtered)\n",
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many NaNs in the data, these can be \"imputed\" with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.impute_nans(data_filtered)\n",
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it can be observed the above data is not \"normalized\", we should make features standard scores / z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.normalize_df(data_filtered)\n",
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")\n",
    "print(\"(note remaining outliers above were within the Tukey fences calculated over ALL the data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forms the train / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered[\"target\"] = labels_filtered\n",
    "data_filtered[\"Latitude_EPSG4326\"] = data[\"Latitude_EPSG4326\"]\n",
    "data_filtered[\"Training_CD_Deposit\"] = data[\"Training_CD_Deposit\"]\n",
    "te_df, tr_df, _ = utils.get_spatial_cross_val_idx(data_filtered, test_set=0)\n",
    "tr_df = tr_df.drop(columns=[\"Training_CD_Deposit\"])\n",
    "te_df = te_df.drop(columns=[\"Training_CD_Deposit\"])\n",
    "\n",
    "# test_set = 1 closest split counts in paper\n",
    "print(f\"Train counts: {tr_df['target'].value_counts()}\")\n",
    "print(f\"Test counts: {te_df['target'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gbm_classifier = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.3,\n",
    "    max_iter=70,              # Number of boosting iterations (equivalent to n_estimators)\n",
    "    max_depth=6,              # Maximum tree depth\n",
    "    min_samples_leaf=48,      # Minimum samples required for a leaf node\n",
    "    max_leaf_nodes=64,        # Maximum number of leaf nodes\n",
    "    verbose=1                 # Show progress bars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = 500\n",
    "hist_gbm_classifier.fit(tr_df.drop(columns=['target','Latitude_EPSG4326','group']), tr_df['target'], sample_weight=gain*tr_df['target'].astype('int')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hist_gbm_classifier.predict(tr_df.drop(columns=['target','Latitude_EPSG4326','group']))\n",
    "auc_score = roc_auc_score(tr_df[\"target\"], y_pred)\n",
    "print(f\"Train AUC score:{auc_score}\")\n",
    "\n",
    "y_pred = hist_gbm_classifier.predict(te_df.drop(columns=['target','Latitude_EPSG4326','group']))\n",
    "auc_score = roc_auc_score(te_df['target'], y_pred)\n",
    "print(f\"Test AUC score:{auc_score}\")\n",
    "\n",
    "all_df = pd.concat([tr_df, te_df])\n",
    "y_pred = hist_gbm_classifier.predict(all_df.drop(columns=['target','Latitude_EPSG4326','group']))\n",
    "auc_score = roc_auc_score(all_df[\"target\"], y_pred)\n",
    "print(f\"All AUC score:{auc_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('ta3-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a889bf86c571e47d694f89bf6d4cbe88127ce72526efd7473fd0231b3a36577b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
