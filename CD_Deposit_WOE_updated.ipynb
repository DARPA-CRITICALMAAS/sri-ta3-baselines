{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_dataset()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies presence / absence columns to boolean - geology properties\n",
    "data[\"Geology_Dictionary_Alkalic\"] = data[\"Geology_Dictionary_Alkalic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Anatectic\"] = data[\"Geology_Dictionary_Anatectic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Calcareous\"] = data[\"Geology_Dictionary_Calcareous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Carbonaceous\"] = data[\"Geology_Dictionary_Carbonaceous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Cherty\"] = data[\"Geology_Dictionary_Cherty\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_CoarseClastic\"] = data[\"Geology_Dictionary_CoarseClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Evaporitic\"] = data[\"Geology_Dictionary_Evaporitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Felsic\"] = data[\"Geology_Dictionary_Felsic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_FineClastic\"] = data[\"Geology_Dictionary_FineClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Gneissose\"] = data[\"Geology_Dictionary_Gneissose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Igneous\"] = data[\"Geology_Dictionary_Igneous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Intermediate\"] = data[\"Geology_Dictionary_Intermediate\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Pegmatitic\"] = data[\"Geology_Dictionary_Pegmatitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_RedBed\"] = data[\"Geology_Dictionary_RedBed\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Schistose\"] = data[\"Geology_Dictionary_Schistose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Sedimentary\"] = data[\"Geology_Dictionary_Sedimentary\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_UltramaficMafic\"] = data[\"Geology_Dictionary_UltramaficMafic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "# modifies presence / absence columns to boolean - labels\n",
    "data[\"Training_MVT_Deposit\"] = data[\"Training_MVT_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_MVT_Occurrence\"] = data[\"Training_MVT_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Deposit\"] = data[\"Training_CD_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Occurrence\"] = data[\"Training_CD_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects the data /labels used for MVT WOE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = utils.load_features_dict(type='MVT', baseline='updated')\n",
    "data_filtered, cols = utils.extract_cols(data, cols_dict)\n",
    "\n",
    "data_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function finds all the neighbors and creates a new column \"MVT_Deposit\".\n",
    "Original paper treats neighbors of polygons with \"Training_MVT_Deposit=Present\" and \"Training_MVT_Occurrence=Present\" as mineral present, \"MVT_Deposit=Present\" (note: now Deposit means - Deposit, Occurrence, or their neighbor). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.neighbor_deposits(data_filtered, type='MVT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered['MVT_Deposit'].value_counts())\n",
    "print(data_filtered['MVT_Deposit_wNeighbors'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = data_filtered['MVT_Deposit_wNeighbors']\n",
    "data_filtered = data_filtered.drop(columns=['H3_Geometry', 'Training_MVT_Deposit', 'Training_MVT_Occurrence', 'MVT_Deposit', 'MVT_Deposit_wNeighbors'])\n",
    "cols = cols[1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the dataset has MANY outliers, as reported in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove these outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.tukey_remove_outliers(data_filtered)\n",
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many NaNs in the data, these can be \"imputed\" with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.impute_nans(data_filtered)\n",
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it can be observed the above data is not \"normalized\", we should make features standard scores / z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.normalize_df(data_filtered)\n",
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")\n",
    "print(\"(note remaining outliers above were within the Tukey fences calculated over ALL the data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretizes the continuous variables in 5 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 5\n",
    "for col in cols:\n",
    "    if data_filtered[col].dtype != \"float64\": continue\n",
    "    data_filtered[col] = pd.qcut(data_filtered[col], nbins)\n",
    "data_filtered[\"target\"] = labels_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forms the train / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered[\"Latitude_EPSG4326\"] = data[\"Latitude_EPSG4326\"]\n",
    "data_filtered[\"Training_MVT_Deposit\"] = data[\"Training_MVT_Deposit\"]\n",
    "te_df, tr_df, _ = utils.get_spatial_cross_val_idx(data_filtered, test_set=1, split_col=\"Training_MVT_Deposit\", nbins=36)\n",
    "tr_df = tr_df.drop(columns=[\"Training_MVT_Deposit\"])\n",
    "te_df = te_df.drop(columns=[\"Training_MVT_Deposit\"])\n",
    "\n",
    "# test_set = 1 closest split counts in paper\n",
    "print(f\"Train counts: {tr_df['target'].value_counts()}\")\n",
    "print(f\"Test counts: {te_df['target'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes WOE / IV for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "IV_df = pd.DataFrame(columns=['Variable','IV'])\n",
    "for col in cols:\n",
    "    df, iv = utils.calculate_woe_iv(tr_df, col, 'target')\n",
    "    lst.append(df)\n",
    "    IV_df = pd.concat([IV_df, pd.DataFrame([{\"Variable\": col ,\"IV\": iv,}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the WOE data into the existig input datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the overall IV for all variables on MVT deposits/occurences\n",
    "print(f\"Information Value Overview:\\n{IV_df.sort_values('IV', ascending=False)}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the WOE for all variables on MVT deposits/occurences\n",
    "tr_result = tr_df\n",
    "te_result = te_df\n",
    "all_result = pd.concat([tr_result, te_result])\n",
    "for i, col in enumerate(cols):\n",
    "    col_data = lst[i]\n",
    "    col_data = col_data.rename(columns={\"Value\":col,\"WoE\":f\"{col}_WoE\", \"IV\":f\"{col}_IV\"})\n",
    "    tr_result = pd.merge(tr_result, col_data[[col,f\"{col}_WoE\",f\"{col}_IV\"]], on=col)\n",
    "    te_result = pd.merge(te_result, col_data[[col,f\"{col}_WoE\",f\"{col}_IV\"]], on=col)\n",
    "    all_result = pd.merge(all_result, col_data[[col,f\"{col}_WoE\",f\"{col}_IV\"]], on=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines the WOE for each comlumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_result[\"WOE Total\"] = tr_result.loc[:,[f\"{col}_WoE\" for col in cols]].sum(axis=1)\n",
    "te_result[\"WOE Total\"] = te_result.loc[:,[f\"{col}_WoE\" for col in cols]].sum(axis=1)\n",
    "all_result[\"WOE Total\"] = all_result.loc[:,[f\"{col}_WoE\" for col in cols]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(tr_result[\"target\"],tr_result[\"WOE Total\"])\n",
    "print(f\"Train AUC score:{auc_score}\")\n",
    "auc_score = roc_auc_score(te_result[\"target\"],te_result[\"WOE Total\"])\n",
    "print(f\"Test AUC score:{auc_score}\")\n",
    "auc_score = roc_auc_score(all_result[\"target\"],all_result[\"WOE Total\"])\n",
    "print(f\"All AUC score:{auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - results above differ depending on the test split chosen (higher or lower). Lawley'22 reported using fold 5 of 6 for test split, above we're using 2 of 6 because it had the closest number of train / test example reported in the paper. Our IV values for all variables are largely similar to the Lawley'22 Figure 11a, again not identical due to differences in particular examples chosen as test set.\n",
    "\n",
    "Long-term plan should be to report averaged results across several splits instead - should give more consistent result that is recreatable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('ta3-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a889bf86c571e47d694f89bf6d4cbe88127ce72526efd7473fd0231b3a36577b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
