{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e35547/Library/Python/3.9/lib/python/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿\"H3_Address\"</th>\n",
       "      <th>H3_Resolution</th>\n",
       "      <th>H3_Geometry</th>\n",
       "      <th>Longitude_EPSG4326</th>\n",
       "      <th>Latitude_EPSG4326</th>\n",
       "      <th>Continent_Majority</th>\n",
       "      <th>Continent_Minority</th>\n",
       "      <th>Country_Majority</th>\n",
       "      <th>Country_Minority</th>\n",
       "      <th>Province_Majority</th>\n",
       "      <th>...</th>\n",
       "      <th>Litmod_Density_Asthenosphere</th>\n",
       "      <th>Litmod_Density_Crust</th>\n",
       "      <th>Litmod_Density_Lithosphere</th>\n",
       "      <th>Crust1_Type</th>\n",
       "      <th>Crust1_CrustalThickness</th>\n",
       "      <th>Crust1_SedimentThickness</th>\n",
       "      <th>Training_MVT_Deposit</th>\n",
       "      <th>Training_MVT_Occurrence</th>\n",
       "      <th>Training_CD_Deposit</th>\n",
       "      <th>Training_CD_Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712e579bffffff</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-115.0314 54.5077, -115.0393 54.4961...</td>\n",
       "      <td>-115.018142</td>\n",
       "      <td>54.497221</td>\n",
       "      <td>North America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>3480.580078</td>\n",
       "      <td>2891.260254</td>\n",
       "      <td>3337.300049</td>\n",
       "      <td>island arc</td>\n",
       "      <td>-38.450497</td>\n",
       "      <td>2991.459961</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8712e579affffff</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-115.0658 54.51706, -115.0737 54.505...</td>\n",
       "      <td>-115.052542</td>\n",
       "      <td>54.506590</td>\n",
       "      <td>North America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>3480.580078</td>\n",
       "      <td>2891.260010</td>\n",
       "      <td>3337.300293</td>\n",
       "      <td>island arc</td>\n",
       "      <td>-38.430000</td>\n",
       "      <td>3000.000244</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8712e56b4ffffff</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-115.0604 54.49501, -115.0682 54.483...</td>\n",
       "      <td>-115.047107</td>\n",
       "      <td>54.484541</td>\n",
       "      <td>North America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>3480.580078</td>\n",
       "      <td>2891.259766</td>\n",
       "      <td>3337.300049</td>\n",
       "      <td>island arc</td>\n",
       "      <td>-38.430000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8712e56b5ffffff</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-115.026 54.48564, -115.0338 54.4740...</td>\n",
       "      <td>-115.012729</td>\n",
       "      <td>54.475169</td>\n",
       "      <td>North America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>3480.580078</td>\n",
       "      <td>2891.260010</td>\n",
       "      <td>3337.300049</td>\n",
       "      <td>island arc</td>\n",
       "      <td>-38.591599</td>\n",
       "      <td>2932.666504</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8712e56a6ffffff</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-114.997 54.49832, -115.0049 54.4867...</td>\n",
       "      <td>-114.983753</td>\n",
       "      <td>54.487840</td>\n",
       "      <td>North America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>3480.580078</td>\n",
       "      <td>2891.260010</td>\n",
       "      <td>3337.300049</td>\n",
       "      <td>island arc</td>\n",
       "      <td>-39.815273</td>\n",
       "      <td>2422.801758</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿\"H3_Address\"  H3_Resolution  \\\n",
       "0  8712e579bffffff              7   \n",
       "1  8712e579affffff              7   \n",
       "2  8712e56b4ffffff              7   \n",
       "3  8712e56b5ffffff              7   \n",
       "4  8712e56a6ffffff              7   \n",
       "\n",
       "                                         H3_Geometry  Longitude_EPSG4326  \\\n",
       "0  POLYGON ((-115.0314 54.5077, -115.0393 54.4961...         -115.018142   \n",
       "1  POLYGON ((-115.0658 54.51706, -115.0737 54.505...         -115.052542   \n",
       "2  POLYGON ((-115.0604 54.49501, -115.0682 54.483...         -115.047107   \n",
       "3  POLYGON ((-115.026 54.48564, -115.0338 54.4740...         -115.012729   \n",
       "4  POLYGON ((-114.997 54.49832, -115.0049 54.4867...         -114.983753   \n",
       "\n",
       "   Latitude_EPSG4326 Continent_Majority Continent_Minority Country_Majority  \\\n",
       "0          54.497221      North America      North America           Canada   \n",
       "1          54.506590      North America      North America           Canada   \n",
       "2          54.484541      North America      North America           Canada   \n",
       "3          54.475169      North America      North America           Canada   \n",
       "4          54.487840      North America      North America           Canada   \n",
       "\n",
       "  Country_Minority Province_Majority  ... Litmod_Density_Asthenosphere  \\\n",
       "0           Canada           Alberta  ...                  3480.580078   \n",
       "1           Canada           Alberta  ...                  3480.580078   \n",
       "2           Canada           Alberta  ...                  3480.580078   \n",
       "3           Canada           Alberta  ...                  3480.580078   \n",
       "4           Canada           Alberta  ...                  3480.580078   \n",
       "\n",
       "  Litmod_Density_Crust Litmod_Density_Lithosphere Crust1_Type  \\\n",
       "0          2891.260254                3337.300049  island arc   \n",
       "1          2891.260010                3337.300293  island arc   \n",
       "2          2891.259766                3337.300049  island arc   \n",
       "3          2891.260010                3337.300049  island arc   \n",
       "4          2891.260010                3337.300049  island arc   \n",
       "\n",
       "   Crust1_CrustalThickness Crust1_SedimentThickness Training_MVT_Deposit  \\\n",
       "0               -38.450497              2991.459961               Absent   \n",
       "1               -38.430000              3000.000244               Absent   \n",
       "2               -38.430000              3000.000000               Absent   \n",
       "3               -38.591599              2932.666504               Absent   \n",
       "4               -39.815273              2422.801758               Absent   \n",
       "\n",
       "  Training_MVT_Occurrence Training_CD_Deposit Training_CD_Occurrence  \n",
       "0                  Absent              Absent                 Absent  \n",
       "1                  Absent              Absent                 Absent  \n",
       "2                  Absent              Absent                 Absent  \n",
       "3                  Absent              Absent                 Absent  \n",
       "4                  Absent              Absent                 Absent  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = utils.load_dataset()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies presence / absence columns to boolean - geology properties\n",
    "data[\"Geology_Dictionary_Alkalic\"] = data[\"Geology_Dictionary_Alkalic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Anatectic\"] = data[\"Geology_Dictionary_Anatectic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Calcareous\"] = data[\"Geology_Dictionary_Calcareous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Carbonaceous\"] = data[\"Geology_Dictionary_Carbonaceous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Cherty\"] = data[\"Geology_Dictionary_Cherty\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_CoarseClastic\"] = data[\"Geology_Dictionary_CoarseClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Evaporitic\"] = data[\"Geology_Dictionary_Evaporitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Felsic\"] = data[\"Geology_Dictionary_Felsic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_FineClastic\"] = data[\"Geology_Dictionary_FineClastic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Gneissose\"] = data[\"Geology_Dictionary_Gneissose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Igneous\"] = data[\"Geology_Dictionary_Igneous\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Intermediate\"] = data[\"Geology_Dictionary_Intermediate\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Pegmatitic\"] = data[\"Geology_Dictionary_Pegmatitic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_RedBed\"] = data[\"Geology_Dictionary_RedBed\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Schistose\"] = data[\"Geology_Dictionary_Schistose\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_Sedimentary\"] = data[\"Geology_Dictionary_Sedimentary\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Geology_Dictionary_UltramaficMafic\"] = data[\"Geology_Dictionary_UltramaficMafic\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "# modifies presence / absence columns to boolean - labels\n",
    "data[\"Training_MVT_Deposit\"] = data[\"Training_MVT_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_MVT_Occurrence\"] = data[\"Training_MVT_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Deposit\"] = data[\"Training_CD_Deposit\"].apply(lambda x: True if x == \"Present\" else False)\n",
    "data[\"Training_CD_Occurrence\"] = data[\"Training_CD_Occurrence\"].apply(lambda x: True if x == \"Present\" else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects the data /labels used for MVT WOE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = utils.load_features_dict(type='MVT', baseline='preferred')\n",
    "data_filtered, cols = utils.extract_cols(data, cols_dict)\n",
    "\n",
    "data_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function finds all the neighbors and creates a new column \"MVT_Deposit\".\n",
    "Original paper treats neighbors of polygons with \"Training_MVT_Deposit=Present\" and \"Training_MVT_Occurrence=Present\" as mineral present, \"MVT_Deposit=Present\" (note: now Deposit means - Deposit, Occurrence, or their neighbor). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.neighbor_deposits(data_filtered, type='MVT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered['MVT_Deposit'].value_counts())\n",
    "print(data_filtered['MVT_Deposit_wNeighbors'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = data_filtered['MVT_Deposit_wNeighbors']\n",
    "data_filtered = data_filtered.drop(columns=['H3_Geometry', 'Training_MVT_Deposit', 'Training_MVT_Occurrence', 'MVT_Deposit', 'MVT_Deposit_wNeighbors'])\n",
    "cols = cols[1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the dataset has MANY outliers, as reported in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = pd.get_dummies(data_filtered, columns=['Geology_Lithology_Majority','Geology_Lithology_Minority','Geology_Period_Maximum_Majority','Geology_Period_Minimum_Majority'], prefix=['Geology_Lithology_Majority','Geology_Lithology_Minority','Geology_Period_Maximum_Majority','Geology_Period_Minimum_Majority'])\n",
    "data_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove these outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.tukey_remove_outliers(data_filtered)\n",
    "# ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also many NaNs in the data, these can be \"imputed\" with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.impute_nans(data_filtered)\n",
    "print(data_filtered.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it can be observed the above data is not \"normalized\", we should make features standard scores / z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = utils.normalize_df(data_filtered)\n",
    "ax = sns.boxplot(data=data_filtered, orient=\"h\", palette=\"Set2\")\n",
    "print(\"(note remaining outliers above were within the Tukey fences calculated over ALL the data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending 'target' column to data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sedimentary_Dictionary', 'Igneous_Dictionary',\n",
       "       'Metamorphic_Dictionary', 'Seismic_LAB_Priestley', 'Seismic_Moho',\n",
       "       'Gravity_GOCE_ShapeIndex', 'Geology_Paleolatitude_Period_Minimum',\n",
       "       'Terrane_Proximity', 'Geology_PassiveMargin_Proximity',\n",
       "       'Geology_BlackShale_Proximity', 'Geology_Fault_Proximity',\n",
       "       'Gravity_Bouguer', 'Gravity_Bouguer_HGM',\n",
       "       'Gravity_Bouguer_UpCont30km_HGM', 'Gravity_Bouguer_HGM_Worms_Proximity',\n",
       "       'Gravity_Bouguer_UpCont30km_HGM_Worms_Proximity', 'Magnetic_HGM',\n",
       "       'Magnetic_LongWavelength_HGM', 'Magnetic_HGM_Worms_Proximity',\n",
       "       'Magnetic_LongWavelength_HGM_Worms_Proximity',\n",
       "       'Geology_Lithology_Majority_Igneous_Extrusive',\n",
       "       'Geology_Lithology_Majority_Igneous_Intrusive_Felsic',\n",
       "       'Geology_Lithology_Majority_Igneous_Intrusive_Mafic',\n",
       "       'Geology_Lithology_Majority_Metamorphic_Gneiss',\n",
       "       'Geology_Lithology_Majority_Metamorphic_Gneiss_Paragneiss',\n",
       "       'Geology_Lithology_Majority_Metamorphic_Schist',\n",
       "       'Geology_Lithology_Majority_Other_Unconsolidated',\n",
       "       'Geology_Lithology_Majority_Sedimentary_Chemical',\n",
       "       'Geology_Lithology_Majority_Sedimentary_Siliciclastic',\n",
       "       'Geology_Lithology_Minority_Igneous_Extrusive',\n",
       "       'Geology_Lithology_Minority_Igneous_Intrusive_Felsic',\n",
       "       'Geology_Lithology_Minority_Igneous_Intrusive_Mafic',\n",
       "       'Geology_Lithology_Minority_Metamorphic_Gneiss',\n",
       "       'Geology_Lithology_Minority_Metamorphic_Gneiss_Paragneiss',\n",
       "       'Geology_Lithology_Minority_Metamorphic_Schist',\n",
       "       'Geology_Lithology_Minority_Other_Unconsolidated',\n",
       "       'Geology_Lithology_Minority_Sedimentary_Chemical',\n",
       "       'Geology_Lithology_Minority_Sedimentary_Siliciclastic',\n",
       "       'Geology_Period_Maximum_Majority_Cambrian',\n",
       "       'Geology_Period_Maximum_Majority_Cretaceous',\n",
       "       'Geology_Period_Maximum_Majority_Devonian',\n",
       "       'Geology_Period_Maximum_Majority_Eoarchean',\n",
       "       'Geology_Period_Maximum_Majority_Jurassic',\n",
       "       'Geology_Period_Maximum_Majority_Mesoarchean',\n",
       "       'Geology_Period_Maximum_Majority_Mesoproterozoic',\n",
       "       'Geology_Period_Maximum_Majority_Mississippian',\n",
       "       'Geology_Period_Maximum_Majority_Neoarchean',\n",
       "       'Geology_Period_Maximum_Majority_Neogene',\n",
       "       'Geology_Period_Maximum_Majority_Neoproterozoic',\n",
       "       'Geology_Period_Maximum_Majority_Ordovician',\n",
       "       'Geology_Period_Maximum_Majority_Paleoarchean',\n",
       "       'Geology_Period_Maximum_Majority_Paleogene',\n",
       "       'Geology_Period_Maximum_Majority_Paleoproterozoic',\n",
       "       'Geology_Period_Maximum_Majority_Pennsylvanian',\n",
       "       'Geology_Period_Maximum_Majority_Permian',\n",
       "       'Geology_Period_Maximum_Majority_Quaternary',\n",
       "       'Geology_Period_Maximum_Majority_Silurian',\n",
       "       'Geology_Period_Maximum_Majority_Triassic',\n",
       "       'Geology_Period_Minimum_Majority_Cambrian',\n",
       "       'Geology_Period_Minimum_Majority_Cretaceous',\n",
       "       'Geology_Period_Minimum_Majority_Devonian',\n",
       "       'Geology_Period_Minimum_Majority_Eoarchean',\n",
       "       'Geology_Period_Minimum_Majority_Jurassic',\n",
       "       'Geology_Period_Minimum_Majority_Mesoarchean',\n",
       "       'Geology_Period_Minimum_Majority_Mesoproterozoic',\n",
       "       'Geology_Period_Minimum_Majority_Mississippian',\n",
       "       'Geology_Period_Minimum_Majority_Neoarchean',\n",
       "       'Geology_Period_Minimum_Majority_Neogene',\n",
       "       'Geology_Period_Minimum_Majority_Neoproterozoic',\n",
       "       'Geology_Period_Minimum_Majority_Ordovician',\n",
       "       'Geology_Period_Minimum_Majority_Paleoarchean',\n",
       "       'Geology_Period_Minimum_Majority_Paleogene',\n",
       "       'Geology_Period_Minimum_Majority_Paleoproterozoic',\n",
       "       'Geology_Period_Minimum_Majority_Pennsylvanian',\n",
       "       'Geology_Period_Minimum_Majority_Permian',\n",
       "       'Geology_Period_Minimum_Majority_Quaternary',\n",
       "       'Geology_Period_Minimum_Majority_Silurian',\n",
       "       'Geology_Period_Minimum_Majority_Triassic', 'target',\n",
       "       'Latitude_EPSG4326'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered[\"target\"] = labels_filtered\n",
    "\n",
    "df_result = data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the latitudes to the datacube to make train, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"Latitude_EPSG4326\"] = data[\"Latitude_EPSG4326\"]\n",
    "te_df, tr_df, splits = utils.get_spatial_cross_val_idx(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, val_index) in enumerate(splits):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: groups={np.unique(tr_df.iloc[train_index.tolist()]['group'].tolist())}\")\n",
    "    print(f\"  Val: groups={np.unique(tr_df.iloc[val_index.tolist()]['group'].tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gbm_classifier = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.3,\n",
    "    max_iter=90,              # Number of boosting iterations (equivalent to n_estimators)\n",
    "    max_depth=6,              # Maximum tree depth\n",
    "    min_samples_leaf=48,      # Minimum samples required for a leaf node\n",
    "    max_leaf_nodes=64,        # Maximum number of leaf nodes\n",
    "    verbose=1                 # Show progress bars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = 650\n",
    "hist_gbm_classifier.fit(tr_df.drop(columns=['target','Latitude_EPSG4326','group']), tr_df['target'], sample_weight=gain*tr_df['target'].astype('int')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hist_gbm_classifier.predict(tr_df.drop(columns=['target','Latitude_EPSG4326','group']))\n",
    "auc_score = roc_auc_score(tr_df[\"target\"], y_pred)\n",
    "print(f\"Train AUC score:{auc_score}\")\n",
    "\n",
    "y_pred = hist_gbm_classifier.predict(te_df.drop(columns=['target','Latitude_EPSG4326','group']))\n",
    "auc_score = roc_auc_score(te_df['target'], y_pred)\n",
    "print(f\"Test AUC score:{auc_score}\")\n",
    "\n",
    "y_pred = hist_gbm_classifier.predict(df_result.drop(columns=['target','Latitude_EPSG4326']))\n",
    "auc_score = roc_auc_score(df_result[\"target\"], y_pred)\n",
    "print(f\"All AUC score:{auc_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('ta3-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a889bf86c571e47d694f89bf6d4cbe88127ce72526efd7473fd0231b3a36577b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
